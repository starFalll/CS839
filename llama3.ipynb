{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [14:46<00:00, 221.52s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from json import loads\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:04<00:44,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'description', 'year', 'status'] ['notes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:05<00:45,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['result', 'team', 'name'] ['name']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:06<00:51,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FR Doc.', 'RIN', 'Docket No.'] ['type']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:07<00:45,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', 'zip code'] ['county']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:12<00:39,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Docket No.', 'RIN', 'FR Doc.'] ['type']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:14<00:32,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city', 'country'] ['location']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:16<00:28,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['location', 'distance'] ['city']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:17<00:33,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['team', 'name', 'result', 'category'] ['class']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:19<00:35,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC', 'REMI', 'LAPS', 'FP', 'Effective date'] ['code', 'description']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:22<00:44,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['description', 'option', 'behavior', 'log', 'action', 'file', 'destination', 'update'] ['description']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:23<00:31,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'description'] ['position']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:24<00:26,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'description'] ['name']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:25<00:27,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category', 'description', 'company', 'industry'] ['industry']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:26<00:26,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'region', 'of', 'manufacture'] ['language']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:27<00:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1st', '2nd', '3rd'] ['person']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:33<00:48,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', 'category', 'team', 'status', 'rank', 'year', 'location', 'teamName', 'city', 'state', 'country', 'industry', 'genre', 'company', 'product', 'service', 'album', 'isbn', 'publisher', 'origin', 'birthDate', 'birthPlace', 'education', 'director', 'sales', 'continent', 'organisation'] ['description']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:36<00:17,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['description', 'notes'] ['description']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [00:46<00:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city', 'year'] ['team']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RIN', 'FR Doc.'] ['type']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "template_context = \"\"\"\n",
    "Column Names are limited to the following:\n",
    "name, description, team, type, age, location, year, city, rank, status, state, category,\n",
    "weight, code, club, artist, result, position, country, notes, class, company, album, symbol,\n",
    "address, duration, format, county, day, gender, industry, language, sex, product, jockey,\n",
    "region, area, service, teamName, order, isbn, fileSize, grades, publisher, plays, origin,\n",
    "elevation, affiliation, component, owner, genre,  manufacturer, brand, family, credit, depth,\n",
    "classification, collection, species, command, nationality, currency, range, affiliate,\n",
    "birthDate, ranking, capacity, birthPlace, person, creator, operator, religion, education,\n",
    "requirement, director, sales, continent, organisation\n",
    "Do not use any column names aside from these.\n",
    "\n",
    "Output must be in valid JSON like the following example {\"colnames\" : [\"col1\", \"col2\"]}\n",
    "\n",
    "Given the following relational table:\n",
    "\"\"\"\n",
    "\n",
    "tabledir = \"K4\" # Note that it doesn't end with '/'\n",
    "filenames = os.listdir(tabledir)\n",
    "real_cols = []\n",
    "pred_cols = []\n",
    "#i = 0\n",
    "for filename in tqdm(filenames[0:100]):\n",
    "    with open(tabledir + '/' + filename) as f:\n",
    "        linelist = f.readlines()\n",
    "        colnames = linelist[0][:-1].split(',')\n",
    "        \n",
    "        lines = ''.join(linelist[1:21])#.replace(',',';')\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "        You are a database expert who can make general predictions for missing column values in database tables, and the predicted column names are within the required candidate set. All output must be in valid JSON. Don't add explanation beyond the JSON.\n",
    "        Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "        \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{template_context} \\n {lines} Guess the column names for the whole table. There are only {len(colnames)} columns in the table. It is possible for multiple columns to have the same name.\\n\"},\n",
    "        ]\n",
    "\n",
    "        prompt = pipeline.tokenizer.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        terminators = [\n",
    "            pipeline.tokenizer.eos_token_id,\n",
    "            pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        ]\n",
    "\n",
    "        outputs = pipeline(\n",
    "            prompt,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=terminators,\n",
    "            pad_token_id=pipeline.tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        # print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "        jslist = loads(outputs[0][\"generated_text\"][len(prompt):])\n",
    "        if len(jslist[\"colnames\"]) != len(colnames):\n",
    "            print(jslist[\"colnames\"], colnames)\n",
    "        else:\n",
    "            real_cols += colnames\n",
    "            pred_cols += jslist[\"colnames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"correct = 0\\ntotal = 0\\nfor real,pred in zip(real_cols, pred_cols):\\n    for r,p in zip(real,pred):\\n        total += 1\\n        if r == (p[0].lower() + p[1:]):\\n            correct += 1\\nprint(f'Accuracy: {correct/total}')\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{tabledir}_true.npy', 'wb') as f:\n",
    "    np.save(f, np.array(real_cols, dtype='<U14'))\n",
    "with open(f'{tabledir}_pred.npy', 'wb') as f:\n",
    "    np.save(f, np.array(pred_cols, dtype='<U14'))\n",
    "\"\"\"correct = 0\n",
    "total = 0\n",
    "for real,pred in zip(real_cols, pred_cols):\n",
    "    for r,p in zip(real,pred):\n",
    "        total += 1\n",
    "        if r == (p[0].lower() + p[1:]):\n",
    "            correct += 1\n",
    "print(f'Accuracy: {correct/total}')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "127\n",
      "name name\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_cols))\n",
    "print(len(real_cols))\n",
    "print(real_cols[0], pred_cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
